{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description\n",
    "This notebook contains all code used in the creation of the ToRies_Labprocessed2017_to_2021.csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import dateparser\n",
    "from pytz import timezone\n",
    "import shutil\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir  = '../../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_dir = data_dir + 'SeaGrant-TA_DIC-MassBayData/concat/'\n",
    "metadata_dir = concat_dir + 'metadata/'\n",
    "if not os.path.exists(concat_dir):\n",
    "    os.makedirs(concat_dir)\n",
    "if not os.path.exists(metadata_dir):\n",
    "    os.makedirs(metadata_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SeaGrant-TA_DIC-MassBayData/ Concatentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet2017 = pd.read_excel(data_dir + 'SeaGrant-TA_DIC-MassBayData/ToRies_Labprocessed2017sharedSeaGlass.xlsx',\n",
    "                          sheet_name=None)\n",
    "\n",
    "sheet2018 = pd.read_excel(data_dir + 'SeaGrant-TA_DIC-MassBayData/ToRies_Labprocessed2018_sharedSeaGlass.xlsx',\n",
    "                          sheet_name=None)\n",
    "\n",
    "sheet2019 = pd.read_excel(data_dir + 'SeaGrant-TA_DIC-MassBayData/ToRies_Labprocessed2019_sharedSeaGlass.xlsx',\n",
    "                          sheet_name=None)\n",
    "\n",
    "sheet20202021 = pd.read_excel(data_dir + 'SeaGrant-TA_DIC-MassBayData/ToRies_Labprocessed2020and2021_sharedSeaGlass.xlsx',\n",
    "                          sheet_name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2017 = sheet2017['batch_all2017p']\n",
    "metadata2017 = sheet2017['readme']\n",
    "\n",
    "data2018 = sheet2018['batch_all2018p']\n",
    "metadata2018 = sheet2018['readme']\n",
    "\n",
    "data2019 = sheet2019['batch_all2019p']\n",
    "metadata2019 = sheet2019['readme2019']\n",
    "\n",
    "data20202021 = sheet20202021['batch12_13_14']\n",
    "metadata20202021 = sheet20202021['readme']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix datetime issues 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/becklabash/Library/Python/3.8/lib/python/site-packages/dateparser/date_parser.py:35: PytzUsageWarning: The localize method is no longer necessary, as this time zone supports the fold attribute (PEP 495). For more details on migrating to a PEP 495-compliant implementation, see https://pytz-deprecation-shim.readthedocs.io/en/latest/migration.html\n",
      "  date_obj = stz.localize(date_obj)\n"
     ]
    }
   ],
   "source": [
    "# Convert 2017 data to datetime\n",
    "for ind, row in data2017.iterrows():\n",
    "    date_val = row['SampleDateTime']\n",
    "    if type(date_val) == str:\n",
    "        date = dateparser.parse(date_val)\n",
    "        try:\n",
    "            x = date.strftime(\"%Y\")\n",
    "            if x != \"2017\":\n",
    "                print(date_val)\n",
    "        except:\n",
    "            print(date_val)\n",
    "        data2017.loc[ind, 'SampleDateTime'] = date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix datetime issues 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat unrecognized strings (2018)\n",
    "for ind, row in data2018.iterrows():\n",
    "    if isinstance(row['SampleDateTime'], str):\n",
    "        s = row['SampleDateTime']\n",
    "        if (s[4] != \" \" and s[2] != \" \"):\n",
    "            new_string = s[0:4] + \" \" + s[4:6] + \" \" + s[6:]\n",
    "            data2018.loc[ind, 'SampleDateTime'] = new_string\n",
    "\n",
    "# Convert reformated strings to datetime (2018)\n",
    "for ind, row in data2018.iterrows():\n",
    "    val = row['SampleDateTime']\n",
    "    if isinstance(val, str):\n",
    "        date = dateparser.parse(val)\n",
    "        data2018.loc[ind, 'SampleDateTime'] = date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix datetime issues 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert 2019 data from pandas timestamp to datetime\n",
    "#data2019['SampleDateTime'] = [date.to_pydatetime() for date in data2019['SampleDateTime']]\n",
    "for ind, row in data2019.iterrows():\n",
    "    data2019.loc[ind, 'SampleDateTime'] = row['SampleDateTime'].to_pydatetime()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix datetime issues 2020-2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind, row in data20202021.iterrows():\n",
    "  # If the date is a pandas timestamp, convert to datetime\n",
    "  if isinstance(row['PROF_DATE_TIME_LOCAL'], pd.Timestamp):\n",
    "    data20202021.loc[ind, 'PROF_DATE_TIME_LOCAL'] = row['PROF_DATE_TIME_LOCAL'].to_pydatetime()\n",
    "  # If the date is a string, convert to datetime\n",
    "  elif isinstance(row['PROF_DATE_TIME_LOCAL'], str):\n",
    "    data20202021.loc[ind, 'PROF_DATE_TIME_LOCAL'] = dateparser.parse(row['PROF_DATE_TIME_LOCAL'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix column inconsistencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_conversion = {'BottleLabel': 'Station_D',\n",
    "                      'EVENT_ID': 'SampleID',\n",
    "                      'STAT_ID': 'StationID',\n",
    "                      'PROF_DATE_TIME_LOCAL': 'SampleDateTime',\n",
    "                      'LATITUDE': 'Latitude',\n",
    "                      'LONGITUDE': 'Longitude',\n",
    "                      'DEPTH (m)': 'Depth',\n",
    "                      'CONDTVY (mS/cm)': 'Conductivity',\n",
    "                      'DO_RAW (mg/L)': 'Dissolved Oxygen (Model 43)',\n",
    "                      'FLU_RAW (ug/L)': 'Chla Fluor',\n",
    "                      'PCT_SAT_RAW (PCT)': 'DO % Saturation',\n",
    "                      'pH ()': 'pH <2>',\n",
    "                      'SAL (PSU)': 'Salinity',\n",
    "                      'SIGMA_T ()': 'Sigma-T',\n",
    "                      'TEMP (C)': 'Temperature',\n",
    "                      'TRANS (m-1)': 'Beam Attenuation',\n",
    "                      'AT': 'TA in (mmol/kgSW)',\n",
    "                      'CT': 'TCO2 in (mmol/kgSW)'\n",
    "                      }\n",
    "for col in column_conversion:\n",
    "    data20202021[column_conversion[col]] = data20202021[col]\n",
    "    # Remove the old column\n",
    "    data20202021.drop(col, axis=1, inplace=True)\n",
    "# Remove sampling code column\n",
    "data20202021.drop('Unnamed: 7', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add data source to 20202021\n",
    "data20202021['Data Source'] = 'ToRies_Labprocessed2020and2021_sharedSeaGlass'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate columns and concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection = set(data2017.columns).intersection(set(data2018.columns)).intersection(set(data2019.columns)).intersection(set(data20202021.columns))\n",
    "union = set(data2017.columns).union(set(data2018.columns)).union(set(data2019.columns)).union(set(data20202021.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns not in common: ['Air Irradiance', 'Pressure', 'Field Replicate', 'Salinity - Carolina', 'Water Irradiance', 'Sampling Depth', 'Sampling Date', 'Salinity - Ries ', 'Sampling T', 'Comments', 'Sampled Bottle Name', 'VINDTA Sample Name', 'Run T']\n"
     ]
    }
   ],
   "source": [
    "not_in_common = []\n",
    "for col in union:\n",
    "    if col not in intersection:\n",
    "        not_in_common.append(col)\n",
    "print(f'Columns not in common: {not_in_common}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat = pd.concat([data2017, data2018, data2019, data20202021], sort=False, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add CB Update to StationID and SampleID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_update = pd.read_csv(data_dir + 'SeaGrant-TA_DIC-MassBayData/ToRies_Labprocessed_CB_Update.csv')\n",
    "for ind, row in concat.iterrows():\n",
    "      # Get matching row in mwra batch\n",
    "  match_row = cb_update[\n",
    "    (abs(cb_update['t(oC) out'] - row['t(oC) out']) < 0.0001)\n",
    "  & (abs(cb_update['P (dbars) out'] - row['P (dbars) out']) < 0.0001)\n",
    "  & (abs(cb_update['pH out'] - row['pH out']) < 0.0001)\n",
    "  & (abs(cb_update['fCO2 out (matm)'] - row['fCO2 out (matm)']) < 0.0001)]\n",
    "\n",
    "  if len(match_row) == 1:\n",
    "    concat.loc[ind, 'StationID'] = match_row['StationID'].values[0]\n",
    "    concat.loc[ind, 'SampleID'] = match_row['SampleID'].values[0]\n",
    "    concat.loc[ind, 'Station_D'] = match_row['Station_D'].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format Timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop microseconds and change timzeone to eastern\n",
    "eastern = timezone('US/Eastern')\n",
    "concat['SampleDateTime'] = [date.replace(microsecond=0).replace(tzinfo=eastern) for date in concat['SampleDateTime']]\n",
    "\n",
    "#Convert to excel parsable string\n",
    "concat['SampleDateTime'] = [date.strftime(\"%Y-%m-%d %H:%M:%S%z\") for date in concat['SampleDateTime']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle StationIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strip station ID spaces\n",
    "#concat['STAT_ID'] = [stat.strip(\" \") for stat in concat['STAT_ID']]\n",
    "for ind, row in concat.iterrows():\n",
    "    if type(row['StationID']) == str:\n",
    "        concat.loc[ind, 'StationID'] = row['StationID'].strip(\" \")\n",
    "\n",
    "# Add S identifier to Stellwagen bank station IDs\n",
    "for ind, row in concat.iterrows():\n",
    "  if row['SampleID'] == 'SBNMS':\n",
    "    concat.loc[ind, 'StationID'] = 'S' + row['StationID']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Field Replicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inject val qual column into mwra batch\n",
    "# Get all non-null \n",
    "\n",
    "# Iterate over the rows with a val_qual defined\n",
    "for ind, row in concat.iterrows():\n",
    "\n",
    "  # Get comparator columns\n",
    "  depth = row['Depth']\n",
    "  time = row['SampleDateTime']\n",
    "  \n",
    "  # Get matching row in mwra batch\n",
    "  match_row = concat[\n",
    "    (concat['Depth'] == depth)\n",
    "  & (concat['SampleDateTime'] == time)]\n",
    "\n",
    "  if (len(match_row) == 2):\n",
    "    #print(row['StationID'])\n",
    "    inds = list(match_row.index.values)\n",
    "    concat.loc[inds[0], 'Field Replicate'] = 'Y'\n",
    "    concat.loc[inds[1], 'Field Replicate'] = 'Y'\n",
    "    \n",
    "  if (len(match_row) == 1):\n",
    "    pass\n",
    "\n",
    "  if (len(match_row) > 2):\n",
    "    print(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat.to_csv(data_dir + 'SeaGrant-TA_DIC-MassBayData/concat/ToRies_Labprocessed2017_to_2021.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert metadata to text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_txt(df, txt_file):\n",
    "    row_arr = []\n",
    "    for ind, row in df.iterrows():\n",
    "        cell_arr = []\n",
    "        for cell in row:\n",
    "            if str(cell) == 'nan':\n",
    "                cell_arr.append(\" \")\n",
    "            else:\n",
    "                cell_arr.append(str(cell))\n",
    "\n",
    "        row_arr.append(\" \".join(cell_arr))\n",
    "    out = \"\\n\".join(row_arr)\n",
    "    text_file = open(txt_file, \"w\")\n",
    "    n = text_file.write(out)\n",
    "    text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndf_to_txt(metadata2017,\\n          data_dir + 'SeaGrant-TA_DIC-MassBayData/concat/metadata/ToRies_Labprocessed2017sharedSeaGlass_metadata.txt')\\ndf_to_txt(metadata2018,\\n          data_dir + 'SeaGrant-TA_DIC-MassBayData/concat/metadata/ToRies_Labprocessed2018_sharedSeaGlass_metadata.txt')\\ndf_to_txt(metadata2019,\\n         data_dir + 'SeaGrant-TA_DIC-MassBayData/concat/metadata/ToRies_Labprocessed2019_sharedSeaGlass_metadata.txt')\\ndf_to_txt(metadata20202021,\\ndata_dir + 'SeaGrant-TA_DIC-MassBayData/concat/metadata/ToRies_Labprocessed2020and2021_sharedSeaGlass_metadata.txt')\\n\""
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "df_to_txt(metadata2017,\n",
    "          data_dir + 'SeaGrant-TA_DIC-MassBayData/concat/metadata/ToRies_Labprocessed2017sharedSeaGlass_metadata.txt')\n",
    "df_to_txt(metadata2018,\n",
    "          data_dir + 'SeaGrant-TA_DIC-MassBayData/concat/metadata/ToRies_Labprocessed2018_sharedSeaGlass_metadata.txt')\n",
    "df_to_txt(metadata2019,\n",
    "         data_dir + 'SeaGrant-TA_DIC-MassBayData/concat/metadata/ToRies_Labprocessed2019_sharedSeaGlass_metadata.txt')\n",
    "df_to_txt(metadata20202021,\n",
    "data_dir + 'SeaGrant-TA_DIC-MassBayData/concat/metadata/ToRies_Labprocessed2020and2021_sharedSeaGlass_metadata.txt')\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1 (v3.11.1:a7a450f84a, Dec  6 2022, 15:24:06) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
